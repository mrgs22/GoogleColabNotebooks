{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1BeGPP2q2KUhZLGU1TzagE0EKw799wlEN","timestamp":1697036354220}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"code","metadata":{"id":"evoJuaWZdLKf","executionInfo":{"status":"ok","timestamp":1697395477215,"user_tz":240,"elapsed":7072,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["from collections import OrderedDict\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Jnte6x_dLKi"},"source":["## CompositeLayer is an nn.Module with the following layers (in order):\n","\n","### 1. BatchNorm2d with default parameters\n","### 2. ReLU\n","### 3. Conv2d with kernel_size=1, stride=1, bias=False, all others default values\n","### 4. BatchNorm2d with default parameters\n","### 5. ReLU\n","### 6. Conv2d with kernel_size=3, stride=1, padding=1, bias=False, all others default values\n","\n","#### These layers are connected in a sequential order (i.e., 1-2-3-4-5-6)\n","\n","## Fill the blanks marked by \"##ToAdd:\" in the following cell (30 points)"]},{"cell_type":"code","metadata":{"id":"tzzZdc0xdLKj","executionInfo":{"status":"ok","timestamp":1697395490757,"user_tz":240,"elapsed":351,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["class CompositeLayer(nn.Module):\n","    def __init__(self, num_input_features, num_hidden_features, num_output_features):\n","        \"\"\"\n","        Arguments:\n","            num_input_features: int, num_features for the first BatchNorm2d\n","            num_hidden_features: int, out_channels for the first Conv2d\n","            num_output_features: int, out_channels for the second Conv2d\n","        \"\"\"\n","        super(CompositeLayer, self).__init__()\n","        ##ToAdd: layer BatchNorm2d with default parameters (5 points)\n","        self.bn1 = nn.BatchNorm2d(num_input_features)\n","        ##EndAdd\n","        self.relu1 = nn.ReLU(inplace=True)\n","        ##ToAdd: layer Conv2d with kernel_size=1, stride=1, bias=False, all others default values (5 points)\n","        self.conv1 = nn.Conv2d(num_input_features, num_hidden_features, kernel_size=1, stride=1, bias=False)\n","        ##EndAdd\n","        ##ToAdd: layer BatchNorm2d with default parameters (5 points)\n","        self.bn2 = nn.BatchNorm2d(num_hidden_features)\n","        ##EndAdd\n","        self.relu2 = nn.ReLU(inplace=True)\n","        ##ToAdd: layer Conv2d with kernel_size=3, stride=1, padding=1, bias=False, all others default values (5 points)\n","        self.conv2 = nn.Conv2d(num_hidden_features, num_output_features, kernel_size=3, stride=1, padding=1, bias=False)\n","        ##EndAdd\n","\n","    def forward(self, inputs):\n","        \"\"\"\n","        Args:\n","            inputs: a torch.Tensor or a list of torch.Tensor\n","        \"\"\"\n","        if isinstance(inputs, list):\n","            inputs = torch.cat(inputs, 1)\n","        ##ToAdd: forward pass from inputs to outputs (10 points)\n","        outputs = self.conv2(self.relu2(self.bn2(self.conv1(self.relu1(self.bn1(inputs))))))\n","\n","        ##EndAdd\n","        return outputs"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TIdWjSaadLKk"},"source":["## Block consists of a number (argument `num_layers`) of CompositeLayer defined above:\n","### To illustrate how it works, let's set `num_layers=4` for a Block model.\n","### Then it will have 3 CompositeLayer. Let's name them as `layer1`, `layer2`, `layer3`, and `layer4`.\n","### The input of `layer1` is provided as `init_features` in the `forward` function defined below.\n","### The output of `layer1` will be the input of `layer2`\n","## The output of `layer1` and the output of `layer2` concatenated together at the channel dimension (dim=1) will be the input of `layer3`.\n","## The outputs of `layer1`, `layer2`, and `layer3` concatenated together at the channel dimension (dim=1) will be the input of `layer4`.\n","## So the input of `layer{i}` is the concatenated output of all its previous layers from `layer1` until `layer{i-1}`.\n","## The model `forward` function returns the `init_features` and ALL OUTPUTS of all layers concatenated together at the channel dimension (dim=1)\n","\n","\n","## Fill the blanks marked by \"##ToAdd:\" in the following cell (20 points)"]},{"cell_type":"code","metadata":{"id":"iGO3GwZtdLKl","executionInfo":{"status":"ok","timestamp":1697396992539,"user_tz":240,"elapsed":405,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["class Block(nn.ModuleDict):\n","    def __init__(self, num_layers, num_input_features, num_hidden_features, num_output_features):\n","        \"\"\"\n","        Arguments:\n","            num_layers: int, how many CompositeLayer are included\n","            num_input_features: int, num_input_features for the FIRST CompositeLayer (YOU NEED TO CALCULATE the num_input_features for all other CompositeLayer)\n","            num_hidden_features: int, num_hidden_features for every CompositeLayer\n","            num_output_features: int, num_output_features for every CompositeLayer\n","        \"\"\"\n","        super(Block, self).__init__()\n","        for i in range(num_layers):\n","            ##ToAdd: Add a number of CompositeLayer. Hint: define a CompositeLayer with proper arguments, and use add_module function to add it to self (10 points)\n","            composite_layers = CompositeLayer(num_input_features, num_hidden_features, num_output_features)\n","            self.add_module(f'comp_layer{i+1}', composite_layers)\n","            num_input_features = num_input_features + num_output_features\n","\n","            '''if i == num_layers - 1:\n","              num_input_features = num_output_features'''\n","            ##EndAdd\n","\n","    def forward(self, init_features):\n","        \"\"\"\n","        Arguments:\n","            init_features: torch.Tensor, the input of the first CompositeLayer\n","        \"\"\"\n","        features = [init_features]\n","        ##ToAdd: forward pass. Hint: Append the output of each layer to features one at a time until the last layer (10 points)\n","        for layer in self.values():\n","          features.append(layer(features))\n","\n","        ##EndAdd\n","        return torch.cat(features, 1)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hVDBh5dsdLKl"},"source":["## ConvPool is nn.Sequential with the following layers (in order):\n","\n","### 1. BatchNorm2d with default parameters\n","### 2. ReLU\n","### 3. Conv2d with kernel_size=1, stride=1, bias=False, all others default values\n","### 4. AvgPool2d with kernel_size=2, stride=2, all others default values\n","\n","#### For a subclass of nn.Sequential, you only need to define `__init__` (the `forward` function is already defined in nn.Sequential)\n","\n","## Fill the blanks marked by \"##ToAdd:\" in the following cell (10 points)"]},{"cell_type":"code","metadata":{"id":"CZUJb7PFdLKm","executionInfo":{"status":"ok","timestamp":1697395505036,"user_tz":240,"elapsed":330,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["\n","class ConvPool(nn.Sequential):\n","    def __init__(self, num_input_features, num_output_features):\n","        \"\"\"\n","        Arguments:\n","            num_input_features: int, num_features for the BatchNorm2d layer\n","            num_output_features: int, out_channels for the Conv2d layer\n","        \"\"\"\n","        super(ConvPool, self).__init__()\n","        ##ToAdd: add the layers specified above; hint: use add_module function, e.g., self.add_module('norm', nn.BatchNorm2d(num_input_features)) (10 points)\n","        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n","        self.add_module('conv2d', nn.Conv2d(num_input_features, num_output_features, kernel_size=1, stride=1, bias=False))\n","        self.add_module('avgpool2d', nn.AvgPool2d(kernel_size=2, stride=2))\n","\n","\n","        ##EndAdd"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5kVduQWXdLKm"},"source":["## DenseNet is more complex. It consists multiple Block layers (Note each Block layer consists of multiple CompositeLayer), specified by `block_config`.\n","## The model architecture is as follows:\n","### First convolutional layer (already defined for you) to process the input\n","### A number of Block layers and ConvPool layers you need to add\n","### Final layers such as AvgPool2d and Linear to predict the class labels (already defined for you)\n","\n","\n","## Fill the blanks marked by \"##ToAdd:\" in the following cell (20 points)"]},{"cell_type":"code","metadata":{"id":"ibQBkrmfdLKn","executionInfo":{"status":"ok","timestamp":1697397029109,"user_tz":240,"elapsed":4,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["class DenseNet(nn.Module):\n","    def __init__(self, block_config=(6, 12, 24, 16), num_init_features=64,\n","                 num_hidden_features=128, num_output_features=32, num_classes=10):\n","        \"\"\"\n","        Arguments:\n","            block_config: list of ints, how many layers in Block layer\n","            num_init_features: int, num_input_features for the FIRST Block layer. (You need to calculate the num_input_features for all other Block layers)\n","            num_hidden_features: int, num_hidden_features for ALL Block layers\n","            num_output_features: int, num_output_features for ALL Block layers\n","            num_classes: int, number of classes, out_features for the last Linear layer (already defined for you)\n","        \"\"\"\n","        super(DenseNet, self).__init__()\n","\n","        # First convolution already defined for you\n","        self.features = nn.Sequential(OrderedDict([\n","            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n","            ('norm0', nn.BatchNorm2d(num_init_features)),\n","            ('relu0', nn.ReLU(inplace=True)),\n","            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))]))\n","\n","        # A number of Block and ConvPool layers\n","        num_features = num_init_features #num_features is used as the num_input_features for each Block layer\n","        for i, num_layers in enumerate(block_config):\n","            ##ToAdd: Define a Block layer with num_input_features=num_features (10 points)\n","            block = Block(num_layers, num_features ,num_hidden_features, num_output_features)\n","\n","            ##EndAdd\n","            self.features.add_module(f'block{i+1}', block)\n","            print('1')\n","            ##ToAdd: calculate num_features as the output of the Block layer (5 points)\n","\n","            num_features = num_features+block_config[i] * num_output_features\n","            print(num_features, num_output_features)\n","            ## EndAdd\n","            if i != len(block_config) -1:\n","                # All Block layers Except the last one is followed by a ConvPool layer\n","                # Important: ConvPool layer will reduce the number of features by half\n","                ##ToAdd: add a ConvPool layer with num_input_features=num_features, num_output_features=num_features//2 (5 points)\n","                print('2', block_config, i)\n","                convpool = ConvPool(num_features, num_features//2)\n","\n","                ##EndAdd\n","                self.features.add_module(f'convpool{i+1}', convpool)\n","                # Here we update the num_features, which will be used for the next Block layer in this for loop\n","                num_features = num_features // 2\n","\n","        # Final batch norm\n","        self.features.add_module(f'norm{len(block_config)+1}', nn.BatchNorm2d(num_features))\n","\n","        # Linear layer\n","        self.classifier = nn.Linear(num_features, num_classes)\n","        print('p',num_classes)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        out = F.relu(features, inplace=True)\n","        out = F.adaptive_avg_pool2d(out, (1, 1))\n","        out = torch.flatten(out, 1)\n","        out = self.classifier(out)\n","        return out"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BO5o0ZYVdLKn"},"source":["## Well done!\n","## You don't need to change the following cells. They are here for you to learn how to train a computer vision model in practice\n","## You can also test your implemented DenseNet model using it\n","## If you can build a good DenseNet model (change `block_config`, `num_init_features`, `num_hidden_features`, `num_output_features`) and train it well (change optimizer, learning rate, num_epochs, etc.), you will get some extra credit in case you haven't gotten a perfect score. You are highly recommended to do so!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kReD-hPOdLKo","executionInfo":{"elapsed":18285,"status":"ok","timestamp":1697395530284,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"},"user_tz":240},"outputId":"4b40378a-e4cb-44a5-86c6-5eb2632a32cb"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainset, validationset = torch.utils.data.random_split(trainset, [40000, 10000])\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:13<00:00, 12570644.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKEylL7WdLKp","executionInfo":{"elapsed":2,"status":"ok","timestamp":1697395532934,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"},"user_tz":240},"outputId":"ec72081b-142b-458f-93d3-b5235fe6a27a"},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n","                                          shuffle=True, pin_memory=True, num_workers=4)\n","validationloader = torch.utils.data.DataLoader(validationset, batch_size=1024,\n","                                          shuffle=False, pin_memory=True, num_workers=4)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=1024,\n","                                         shuffle=False, pin_memory=True, num_workers=4)\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5QGeEwqdLKp","executionInfo":{"elapsed":1322,"status":"ok","timestamp":1697397034085,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"},"user_tz":240},"outputId":"e4e3385b-f347-49e0-8ff7-d235091fe0d8"},"source":["writer = SummaryWriter('runs/cifar10')\n","model = DenseNet((4, 8), num_init_features=128, num_hidden_features=256, num_output_features=256, num_classes=10)\n","writer.add_graph(model, torch.randn(1, 3, 32, 32))\n","writer.close()"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1152 256\n","2 (4, 8) 0\n","1\n","2624 256\n","p 10\n"]}]},{"cell_type":"code","metadata":{"id":"TaFCyHsOdLKp","executionInfo":{"status":"ok","timestamp":1697397038532,"user_tz":240,"elapsed":293,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"}}},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.device_count() > 1:\n","    model = torch.nn.DataParallel(model).to(device)\n","else:\n","    model = model.to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","def get_acc(model, loader):\n","    with torch.no_grad():\n","        correct = 0\n","        for i, data in enumerate(loader):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            correct += (labels == outputs.argmax(dim=1).squeeze()).sum()\n","        acc = float(correct) / len(loader.dataset)\n","    return acc"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"5YwsFZo7dLKp","executionInfo":{"elapsed":50238,"status":"error","timestamp":1697397092020,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"},"user_tz":240},"outputId":"8d52ab65-b3bd-4c46-e564-4d1a940aca16"},"source":["num_epochs = 10\n","eval_every = 100\n","train_acc_his = []\n","val_acc_his = []\n","test_acc_his = []\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","    for i, data in enumerate(trainloader):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i==0 or (i+1) % eval_every == 0:\n","            train_acc = get_acc(model, trainloader)\n","            val_acc = get_acc(model, validationloader)\n","            test_acc = get_acc(model, testloader)\n","            train_acc_his.append(train_acc)\n","            val_acc_his.append(val_acc)\n","            test_acc_his.append(test_acc)\n","            writer.add_scalar('train_acc', train_acc, len(train_acc_his))\n","            writer.add_scalar('val_acc', val_acc, len(val_acc_his))\n","            writer.add_scalar('test_acc', test_acc, len(test_acc_his))\n","            print('[epoch %d, iter %d] train_acc: %.3f  val_acc: %.3f  test_acc: %.3f' %\n","                  (epoch+1, i+1, train_acc, val_acc, test_acc))"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["[epoch 1, iter 1] train_acc: 0.119  val_acc: 0.119  test_acc: 0.119\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-670fbe2db4b6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtrain_acc_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mval_acc_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-e61ce7a250b7>\u001b[0m in \u001b[0;36mget_acc\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"bmegmtaidLKq","executionInfo":{"elapsed":125,"status":"error","timestamp":1697140268562,"user":{"displayName":"Gregory Sylvester","userId":"05010306304674874100"},"user_tz":240},"outputId":"c3b74dc8-8b20-4117-b2d5-94e53b8f4ced"},"source":["plt.plot(train_acc_his, 'ro-', label='train')\n","plt.plot(val_acc_his, 'bv-', label='validation')\n","plt.plot(test_acc_his, 'g+-', label='test')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Step')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-d444a06695af>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_his\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_his\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bv-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc_his\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g+-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_acc_his' is not defined"]}]}]}